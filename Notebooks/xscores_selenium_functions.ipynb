{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0904399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from YourInfo import chromedriver_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204157e6",
   "metadata": {},
   "source": [
    "---\n",
    "### This function scrapes an xscores page for games yet to be played in the current season in a selected country and league. Returns a dataframe.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2b698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_xscores_upcoming(country, league_name):\n",
    "#create xscores url string\n",
    "    url = 'https://www.xscores.com/soccer/' + country + '/' + league_name + '/fixtures/2022-2023'\n",
    "\n",
    "#initialize webdriver\n",
    "    path = chromedriver_path\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "#empty df is created in case webpage doesn't load\n",
    "    df = pd.DataFrame(columns = ['Round','Date','Time','Home_Team','Home_Score','Away_Score','Away_Team',\n",
    "                                     'Home_Score_AET','Away_Score_AET','Home_Penalties','Away_Penalties',\n",
    "                                     'Home_Points','Away_Points'])\n",
    "\n",
    "#wait 15 seconds for page to load, proceed to else statement if score elements are detected\n",
    "    try:\n",
    "        elem = WebDriverWait(driver, 30\n",
    "                            ).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.match_home_txt')))\n",
    "        \n",
    "#if webpage doesn't load, error is printed and nothing is scraped\n",
    "    except:\n",
    "        print('URL not scraped: ', url)\n",
    "\n",
    "#if there are no exception, scraping begins\n",
    "    else:\n",
    "        \n",
    "#homes teams\n",
    "        home_team_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_home_txt')\n",
    "        home_teams = [i.text for i in home_team_elements[1:] ]\n",
    "        \n",
    "#away teams\n",
    "        away_team_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_away_txt')\n",
    "        away_teams = [ i.text for i in away_team_elements[1:] ]\n",
    "            \n",
    "#dates & times\n",
    "        dates_times_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'round_date') or contains(@class, 'match_ko')]\")\n",
    "        dates_times = [ i.text for i in dates_times_elements[1:] ]\n",
    "#rounds & times\n",
    "        rounds_times_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'match_ko') or contains(@class, 'round_name')]\")\n",
    "        rounds_times = [ i.text for i in rounds_times_elements[1:] ]\n",
    "        \n",
    "#dates\n",
    "        date_elements = driver.find_elements(By.CSS_SELECTOR, 'div.round_date')\n",
    "        dates = [ i.text for i in date_elements ]\n",
    "            \n",
    "#rounds\n",
    "        round_elements = driver.find_elements(By.CSS_SELECTOR, 'div.round_name')\n",
    "        rounds = [ i.text for i in round_elements ]\n",
    "        \n",
    "#times\n",
    "        time_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_ko')\n",
    "        times = [ i.text for i in time_elements[1:] ]\n",
    "        \n",
    "        driver.quit()   #end scraping\n",
    "\n",
    "        \n",
    "#get date indices\n",
    "        dates_times = pd.Series(dates_times)\n",
    "        date_indices = list( dates_times[ dates_times.isin(dates) ].index )\n",
    "        \n",
    "#prepare dates column:\n",
    "# The difference between date indices (minus one) is the number of games played on the date of the first index.\n",
    "# The difference is used as the number of times that date must be repeated in the final dates column to correctly\n",
    "# correspond to the games.\n",
    "        date_column = []\n",
    "        for i in range(len(date_indices)-1):\n",
    "            date_to_add = dates_times[ date_indices[i] ]\n",
    "    \n",
    "            index_diff = date_indices[i+1] - date_indices[i]\n",
    "    \n",
    "            num_games = (index_diff - 1)\n",
    "    \n",
    "            date_column.extend( num_games * [date_to_add] )\n",
    "\n",
    "        date_column.extend( (len(dates_times) - date_indices[-1] - 1) * [dates_times[date_indices[-1]]] )\n",
    "        # ^ this line accounts for the last date recorded, which doesn't have a later date to compare indices.\n",
    "\n",
    "#get round indicies\n",
    "        rounds_times = pd.Series(rounds_times)\n",
    "        round_indices = list( rounds_times[ rounds_times.isin(rounds) ].index )\n",
    "                \n",
    "#prepare rounds column:\n",
    "#The same process is repeated here for the rounds column.\n",
    "        round_column = []\n",
    "        for i in range(len(round_indices)-1):\n",
    "            round_to_add = rounds_times[ round_indices[i] ]\n",
    "    \n",
    "            index_diff = round_indices[i+1] - round_indices[i]\n",
    "    \n",
    "            num_games = (index_diff - 1)\n",
    "    \n",
    "            round_column.extend( num_games * [round_to_add] )\n",
    "        \n",
    "        round_column.extend( (len(rounds_times) - round_indices[-1] - 1) * [rounds_times[round_indices[-1]]] )\n",
    "        \n",
    "        \n",
    "\n",
    "#create df, score columns are included to match data structure of completed games df\n",
    "        df = pd.DataFrame({\n",
    "            'Round':round_column,\n",
    "            'Date':date_column,\n",
    "            'Time':times,\n",
    "            'Home_Team':home_teams,\n",
    "            'Home_Score':np.nan,\n",
    "            'Away_Score':np.nan,\n",
    "            'Away_Team':away_teams,\n",
    "            'Home_Score_AET':np.nan,\n",
    "            'Away_Score_AET':np.nan,\n",
    "            'Home_Penalties':np.nan,\n",
    "            'Away_Penalties':np.nan,\n",
    "            'Home_Points':np.nan,\n",
    "            'Away_Points':np.nan\n",
    "            })\n",
    "\n",
    "#return df regardless of ealier results\n",
    "    finally:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d84b7e9",
   "metadata": {},
   "source": [
    "---\n",
    "### This function scrapes an xscores page for the completed games played in a selected season for a selected country and league. Returns a dataframe.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "043995aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_xscores_completed(year, country, league_name):\n",
    "#create xscores url string\n",
    "    url = 'https://www.xscores.com/soccer/' + country + '/' + league_name + '/results/' + str(year) + '-' + str(year+1)\n",
    "\n",
    "#initialize webdriver\n",
    "    path = chromedriver_path\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "#empty df is created in case webpage doesn't load\n",
    "    df = pd.DataFrame(columns = ['Round','Date','Time','Home_Team','Home_Score','Away_Score','Away_Team',\n",
    "                                     'Home_Score_AET','Away_Score_AET','Home_Penalties','Away_Penalties',\n",
    "                                     'Home_Points','Away_Points'])\n",
    "\n",
    "#wait 15 seconds for page to load, proceed to else statement if score elements are detected\n",
    "    try:\n",
    "        \n",
    "        elem = WebDriverWait(driver, 30\n",
    "                            ).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.match_ft__home')))\n",
    "        \n",
    "#if webpage doesn't load, error is printed and nothing is scraped\n",
    "    except:\n",
    "        print('URL not scraped: ', url)\n",
    "        \n",
    "#if there' no exception, scraping begins\n",
    "    else:\n",
    "        \n",
    "#scores\n",
    "        scores_element = driver.find_elements(By.CSS_SELECTOR, 'div.match_ft__home')\n",
    "        scores = [ i.text for i in scores_element ]\n",
    "        \n",
    "        home_scores = scores[::2]\n",
    "        away_scores = scores[1::2]\n",
    "\n",
    "#homes teams\n",
    "        home_team_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_home_txt')\n",
    "        home_teams = [ i.text for i in home_team_elements[1:] ]\n",
    "        \n",
    "#away teams\n",
    "        away_team_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_away_txt')\n",
    "        away_teams = [ i.text for i in away_team_elements[1:] ]\n",
    "            \n",
    "#penalties (if any)\n",
    "        penalty_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_pn__home')\n",
    "        penalties = [ i.text for i in penalty_elements ]\n",
    "        \n",
    "        home_pens = penalties[::2]\n",
    "        away_pens = penalties[1::2]\n",
    "        \n",
    "#extra time score (if any)\n",
    "        et_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_et__home')\n",
    "        extra_time = [ i.text for i in et_elements ]\n",
    "        \n",
    "        home_et = extra_time[::2]\n",
    "        away_et = extra_time[1::2]\n",
    "    \n",
    "#dates & times\n",
    "        dates_times_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'round_date') or contains(@class, 'match_ko')]\")\n",
    "        dates_times = [i.text for i in dates_times_elements[1:] ]\n",
    "\n",
    "#rounds & times\n",
    "        rounds_times_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'match_ko') or contains(@class, 'round_name')]\")\n",
    "        rounds_times = [i.text for i in rounds_times_elements[1:] ]\n",
    "        \n",
    "#dates\n",
    "        date_elements = driver.find_elements(By.CSS_SELECTOR, 'div.round_date')\n",
    "        dates = [ i.text for i in date_elements ]\n",
    "            \n",
    "#rounds\n",
    "        round_elements = driver.find_elements(By.CSS_SELECTOR, 'div.round_name')\n",
    "        rounds = [ i.text for i in round_elements ]\n",
    "        \n",
    "#times\n",
    "        time_elements = driver.find_elements(By.CSS_SELECTOR, 'div.match_ko')\n",
    "        times = [ i.text for i in time_elements[1:] ]\n",
    "        \n",
    "        driver.quit()  #end scraping\n",
    "\n",
    "        \n",
    "#get date indices\n",
    "        dates_times = pd.Series(dates_times)\n",
    "        date_indices = list( dates_times[ dates_times.isin(dates) ].index )\n",
    "            \n",
    "#prepare dates column:\n",
    "# The difference between date indices (minus one) is the number of games played on the date of the first index.\n",
    "# The difference is used as the number of times that date must be repeated in the final dates column to correctly\n",
    "# correspond to the games.\n",
    "        date_column = []\n",
    "        for i in range(len(date_indices)-1):\n",
    "            date_to_add = dates_times[ date_indices[i] ]\n",
    "    \n",
    "            index_diff = date_indices[i+1] - date_indices[i]\n",
    "    \n",
    "            num_games = (index_diff - 1)\n",
    "    \n",
    "            date_column.extend( num_games * [date_to_add] )\n",
    "\n",
    "        date_column.extend( (len(dates_times) - date_indices[-1] - 1) * [dates_times[date_indices[-1]]] )\n",
    "        # ^ this line accounts for the last date recorded, which doesn't have a later date to compare indices.\n",
    "\n",
    "#get round indicies\n",
    "        rounds_times = pd.Series(rounds_times)\n",
    "        round_indices = list( rounds_times[ rounds_times.isin(rounds) ].index )\n",
    "                \n",
    "#prepare rounds column\n",
    "#The same process is repeated here for the rounds column.\n",
    "        round_column = []\n",
    "        for i in range(len(round_indices)-1):\n",
    "            round_to_add = rounds_times[ round_indices[i] ]\n",
    "    \n",
    "            index_diff = round_indices[i+1] - round_indices[i]\n",
    "    \n",
    "            num_games = (index_diff - 1)\n",
    "    \n",
    "            round_column.extend( num_games * [round_to_add] )\n",
    "        \n",
    "        round_column.extend( (len(rounds_times) - round_indices[-1] - 1) * [rounds_times[round_indices[-1]]] )\n",
    "\n",
    "    \n",
    "#create df\n",
    "        df = pd.DataFrame({\n",
    "            'Round':round_column,\n",
    "            'Date':date_column,\n",
    "            'Time':times,\n",
    "            'Home_Team':home_teams,\n",
    "            'Home_Score':home_scores,\n",
    "            'Away_Score':away_scores,\n",
    "            'Away_Team':away_teams,\n",
    "            'Home_Score_AET':home_et,\n",
    "            'Away_Score_AET':away_et,\n",
    "            'Home_Penalties':home_pens,\n",
    "            'Away_Penalties':away_pens\n",
    "            })\n",
    "\n",
    "# add home/away points columns for future aggregation\n",
    "        df.loc[(df['Home_Score'].str.isdigit() == True) &\n",
    "           (df['Home_Score'].str.isdigit() == True), \n",
    "           ['Home_Points','Away_Points']] = [1, 1]          #set points to 1 by default\n",
    "\n",
    "        df.loc[ (df['Home_Score']>df['Away_Score']) | \n",
    "            (df['Home_Score_AET']>df['Away_Score_AET']) |\n",
    "            (df['Home_Penalties']>df['Away_Penalties']),\n",
    "            ('Home_Points', 'Away_Points')] = [3, 0]        #set points for case of Home win\n",
    "\n",
    "        df.loc[ (df['Home_Score']<df['Away_Score']) | \n",
    "            (df['Home_Score_AET']<df['Away_Score_AET']) |\n",
    "            (df['Home_Penalties']<df['Away_Penalties']),\n",
    "            ('Home_Points', 'Away_Points')] = [0, 3]        #set points for case of Away win\n",
    "    \n",
    "#return df regardless of ealier results\n",
    "    finally:\n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
